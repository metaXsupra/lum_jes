# -*- coding: utf-8 -*-
"""Informer_lum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Is2NGFHd7Bel6PKbvBcwUcizAohD0r48
"""

from torch.utils.data import TensorDataset
from torch.optim.lr_scheduler import ReduceLROnPlateau
from transformers import InformerConfig, InformerModel, InformerForPrediction, AutoformerForPrediction, AutoformerConfig, PatchTSTConfig, PatchTSTForPrediction
from transformers import AutoTokenizer
from huggingface_hub import hf_hub_download
import torch
import pandas as pd
import numpy as np
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv("engyss.csv")
data.head()

# Remove rows with any NaN values
data = data.dropna()

# Display the cleaned DataFrame
data

data = data.reset_index(drop=True)
for i in range(100):
    print(f"{data['SendTime'][i]} : {data['consumptionValue (kW)'][i]}")

data.keys()

# Combine date and time columns into a single datetime column
data["SendDateTime"] = pd.to_datetime(data["SendDate"] + " " + data["SendTime"], format="%m-%d-%Y %H:%M:%S")

# Extract components into the desired format array
time_feature_array = data["SendDateTime"].apply(lambda x: [x.month, x.day, x.year, x.hour, x.minute, x.second]).tolist()

# Display the time feature array
print(time_feature_array)

print(len(time_feature_array))

lags_seq = []
for i in range(1, 25):
    lags_seq.append(i)

# Initializing an Informer configuration with 12 time steps for prediction
configuration = PatchTSTConfig(prediction_length=1, context_length=24, num_time_features=8, lags_sequence = lags_seq
)

model = PatchTSTForPrediction(configuration)

device = torch.device("cpu")

data.keys()

print(data)

data['SendDateTime'] = pd.to_datetime(data['SendDateTime'])

# Sort the data based on time
data = data.sort_values(by='SendDateTime')

data.shape

data.keys()

data

data.keys()

def create_time_features(data):
    # Extract relevant temporal information
    data['minute'] = data['SendDateTime'].dt.minute
    data['hour'] = data['SendDateTime'].dt.hour
    data['day_of_week'] = data['SendDateTime'].dt.dayofweek
    data['month'] = data['SendDateTime'].dt.month
    data['day'] = data['SendDateTime'].dt.day
    data['year'] = data['SendDateTime'].dt.year

    # Add is_weekend feature
    data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)

    # Initialize the 'time_type' column
    data['time_type'] = 1  # Default to 1 (for the range between 8 and 16)

    # Update 'time_type' based on hour ranges
    data.loc[(data['hour'] >= 21) | (data['hour'] < 8), 'time_type'] = 0  # Night time
    data.loc[(data['hour'] >= 16) & (data['hour'] < 21), 'time_type'] = 2  # Evening

    # Select and return only the required columns as a list of arrays
    selected_columns = ['minute', 'hour', 'day_of_week', 'month', 'day', 'year', 'is_weekend', 'time_type']
    return data[selected_columns].values.tolist()

# Assuming 'data' is your DataFrame
past_time_features = create_time_features(data)

len(past_time_features)

data

data.keys()

data.to_csv("da.csv")

data["SendDateTime"][30]

past_time_features

data.keys()

data.keys()

# Extract features and target
features = data['consumptionValue (kW)'].values
past_time_features

len(features)

features.shape

# Split the data into train and validation sets
features_train, features_val, time_train, time_val = train_test_split(features, past_time_features, test_size=0.25, shuffle=False)

print(len(features_train))
print(len(features_val))
print(len(time_train))
print(len(time_val))

class TimeSeriesDataset(Dataset):
    def __init__(self, price, time, sequence_length, context_length, prediction_length, target_column='PRICE'):
        self.price = price
        self.time = time
        self.sequence_length = sequence_length
        self.context_length = context_length
        self.prediction_length = prediction_length
        self.target_column = target_column

    def __len__(self):
        return len(self.price) - self.sequence_length

    def __getitem__(self, idx):
        x = self.price[idx:idx + self.sequence_length]
        x = torch.tensor(np.asarray(x, dtype=np.float32), dtype=torch.float32)
        xt = self.time[idx:idx + self.sequence_length]
        xt = torch.tensor(np.asarray(xt, dtype=np.float32), dtype=torch.float32)
        #y = self.y[idx + self.sequence_length:idx + 2*self.sequence_length]
        y = self.price[idx + self.sequence_length]
        y = torch.tensor(np.asarray(y, dtype=np.float32), dtype = torch.float32)
        #yt = self.time[idx + self.sequence_length : idx + 2*self.sequence_length]
        yt = self.time[idx + self.sequence_length]
        yt = torch.tensor(np.asarray(yt, dtype=np.float32), dtype=torch.float32)
        #mask = torch.ones([24], dtype=torch.bool)

        # x = x.to(device)
        # xt = xt.to(device)
        # y = y.to(device)
        # yt = yt.to(device)
        #mask = mask.to(device)
        return x, y, xt, yt

train_dataset = TimeSeriesDataset(features_train, time_train, sequence_length=24, context_length=configuration.context_length, prediction_length=configuration.prediction_length)
val_dataset = TimeSeriesDataset(features_val, time_val, sequence_length=24, context_length=configuration.context_length, prediction_length=configuration.prediction_length)

# DataLoader
batch_size = 128
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

model.to(device)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=3e-4)

configuration.prediction_length

configuration

configuration.context_length + max(configuration.lags_sequence)

configuration

model_name = "PatchTST_lum.pt"
min_val_loss = 100
best_epoch = 0
do_train = True

import os

if do_train:
    # Training loop
    num_epochs = 100
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        for batch in train_dataloader:
            pv, fv, ptf, ftf = batch
            pv, fv, ptf, ftf = pv.to(device), fv.to(device), ptf.to(device), ftf.to(device)

            pv = pv.unsqueeze(-1)
            fv = fv.unsqueeze(-1).unsqueeze(-1)
            #past_values = past_values.squeeze()
            #past_observed_mask = torch.ones_like(past_values)

            optimizer.zero_grad()

            #past_values.unsqueeze(1)
            #past_observed_mask = past_observed_mask.squeeze(-1)
            #past_observed_mask = past_observed_mask.unsqueeze(1)
            pom = torch.ones_like(pv)
            #fom = torch.ones_like(fv)

            ftf = ftf.view(ptf.shape[0], fv.shape[1], ptf.shape[2])

            #pv = pv.squeeze()
            # print(pv.shape)
            # print(fv.shape)
            # print(ptf.shape)
            # print(ftf.shape)
            # print(pom.shape)

            outputs = model(past_values=pv, past_observed_mask=pom, future_values=fv)  # Adding a batch dimension

            #print(outputs)
            #print(outputs.size())
            #print(fv.shape)
            loss = outputs.loss
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_train_loss = total_loss / len(train_dataloader)

        # Validation loop
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in val_dataloader:
                pv, fv, ptf, ftf = batch
                pv, fv, ptf, ftf = pv.to(device), fv.to(device), ptf.to(device), ftf.to(device)

                pv = pv.unsqueeze(-1)
                fv = fv.unsqueeze(-1).unsqueeze(-1)

                #past_values = past_values.squeeze()
                #past_observed_mask = torch.ones_like(past_values)

                #optimizer.zero_grad()

                #past_values.unsqueeze(1)
                #past_observed_mask = past_observed_mask.squeeze(-1)
                #past_observed_mask = past_observed_mask.unsqueeze(1)
                pom = torch.ones_like(pv)
                #fom = torch.ones_like(fv)

                ftf = ftf.view(ptf.shape[0], fv.shape[1], ptf.shape[2])

                #print(pv.shape)
                #print(fv.shape)
                #print(ptf.shape)
                #print(ftf.shape)
                #print(pom.shape)
                #pv = pv.squeeze()

                outputs = model(past_values=pv, past_observed_mask=pom, future_values=fv)  # Adding a batch dimension

                #print(outputs)
                #print(outputs.size())
                #print(fv.shape)
                loss = outputs.loss

                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_dataloader)

        if ((min_val_loss - avg_val_loss) > 1e-4):
            min_val_loss = avg_val_loss
            best_epoch = epoch + 1
            torch.save(model.state_dict(), model_name)

        print(f"Epoch : {epoch+1}")
        print(f"Training Loss : {avg_train_loss}")
        print(f"Validation Loss : {avg_val_loss}")
        print("")

        model.load_state_dict(torch.load(model_name))

    print(f"Best Epoch : {best_epoch}")
    print(f"Best Validation Loss : {min_val_loss}")

        #print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}')

model.load_state_dict(torch.load(model_name, map_location=device))

# Function to plot attention heatmap
def plot_attention_heatmap(attention_weights):
    plt.figure(figsize=(10, 8))
    sns.heatmap(attention_weights, cmap='viridis', xticklabels=False, yticklabels=False)
    plt.xlabel('Time Steps')
    plt.ylabel('Time Steps')
    plt.title('Attention Heatmap')
    plt.show()

# Function to plot attention heatmap for aggregated attention weights
def plot_aggregated_attention_heatmap(attention_weights):
    aggregated_attention_weights = np.mean(attention_weights, axis=0)  # Compute mean across batches
    plt.figure(figsize=(10, 8))
    sns.heatmap(aggregated_attention_weights, cmap='viridis', xticklabels=False, yticklabels=False)
    plt.xlabel('Time Steps')
    plt.ylabel('Time Steps')
    plt.title('Aggregated Attention Heatmap')
    plt.show()

print(features_val.shape[0])

# Evaluation
model.eval()
all_predictions = []

batch_size = features_val.shape[0]
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

with torch.no_grad():
    for batch in val_dataloader:
        pv, fv, ptf, ftf = batch
        pv, fv, ptf, ftf = pv.to(device), fv.to(device), ptf.to(device), ftf.to(device)

        pv = pv.unsqueeze(-1)
        fv = fv.unsqueeze(-1).unsqueeze(-1)
        #past_values = past_values.squeeze()
        #past_observed_mask = torch.ones_like(past_values)

        #optimizer.zero_grad()

        #past_values.unsqueeze(1)
        #past_observed_mask = past_observed_mask.squeeze(-1)
        #past_observed_mask = past_observed_mask.unsqueeze(1)
        pom = torch.ones_like(pv)
        #fom = torch.ones_like(fv)

        ftf = ftf.view(ptf.shape[0], fv.shape[1], ptf.shape[2])

        #print(pv.shape)
        #print(fv.shape)
        #print(ptf.shape)
        #print(ftf.shape)
        #print(pom.shape)

        outputs = model.generate(past_values=pv, past_observed_mask=pom)  # Adding a batch dimension

        attention_outputs = model(past_values=pv, past_observed_mask=pom, output_attentions=True)

        mean_prediction = outputs.sequences.mean(dim=1)

        #attention_outputs = outputs.attention_outputs

        all_predictions.extend(mean_prediction)

encoder_attentions = output_attentions.encoder_attentions
cross_attentions = output_attentions.cross_attentions
decoder_attentions = output_attentions.decoder_attentions

for layer, attention_tensor in enumerate(encoder_attentions):
    # Reshape the tensor for easier visualization
    attention_array = attention_tensor.cpu().detach().numpy()  # Convert to numpy array

    # Take the mean along the specified dimensions
    attention_mean = attention_array.mean(axis=(0, 1))  # Take mean along num_heads and batch_size dimensions

    # Plotting the heatmap for the average attention weights
    plt.figure(figsize=(10, 8))
    sns.heatmap(attention_mean, cmap='viridis')
    plt.title(f'Encoder Layer {layer+1} Average Attention Heatmap')
    plt.xlabel('Source Sequence')
    plt.ylabel('Target Sequence')
    plt.savefig(f'Autoformer_Modified_{layer+1}.png')
    plt.show()

print(len(true_values))
print(len(all_predictions))

# Inverse transform predictions to original scale
#all_predictions = scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1))
#print(all_predictions)
#print(all_predictions.shape)

all_prediction = []
for item in all_predictions:
    all_prediction.append(item[0].item())
all_prediction = np.array(all_prediction)
#print(y_val)
true_values = features_val[-len(all_prediction):]
#print(true_values.shape)
#print(all_prediction.shape)
# Calculate RMSE
rmse = np.sqrt(mean_squared_error(true_values, all_prediction))
mae = mean_absolute_error(true_values, all_prediction)
print(f'Root Mean Squared Error (RMSE): {rmse}')
print(f'Mean Absolute Error (MAE): {mae}')

print()

# Plot true values vs predicted values
plt.figure(figsize=(12, 6))
plt.plot(true_values, label='True Values', color='blue')
plt.plot(all_prediction, label='Predicted Values', color='red')
plt.xlabel('Time Steps')
plt.ylabel('Price')
plt.title('True Values vs Predicted Values(PatchTST Modified)')
plt.legend()
plt.savefig('PatchTST_modified.png')
plt.show()











